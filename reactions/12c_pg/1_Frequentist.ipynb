{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tqdm import tqdm\n",
    "from brick.azr import AZR\n",
    "from lmfit import Parameters, Minimizer\n",
    "from IPython.display import display, Math\n",
    "from multiprocess import Pool\n",
    "\n",
    "# Ignore RuntimeWarning\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "\n",
    "# We can change the default minimizer\n",
    "method = \"leastsq\"\n",
    "\n",
    "# Normalization parameter map : { index : (value, error) } (in AZURE2 order)\n",
    "norms = { 0: (1, 0.05), 1: (1, 0.069), 2: (1, 0.079), 3: (1, 0.085), 4: (1, 0.05), 5: (1, 0.10), 6: (1, 0.10) }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We read the .azr file\n",
    "azr = AZR('12c_pg.azr')\n",
    "azr.ext_capture_file='output/intEC.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We get the initial values from AZURE2\n",
    "theta0 = azr.config.get_input_values()\n",
    "\n",
    "# Get number of data points\n",
    "output = np.vstack( azr.predict( theta0, dress_up=False ) )\n",
    "ndata = output.shape[0]\n",
    "\n",
    "# Number of datasets\n",
    "nsegments = len(azr.config.data.segments)\n",
    "\n",
    "# Now we loop over the data files to take their order and length and cut the output\n",
    "index, data = 0, { }\n",
    "for segment in azr.config.data.segments:\n",
    "    data[segment.filename] = output[index:index+len(segment.values)]\n",
    "    index += len(segment.values)\n",
    "\n",
    "# Number of R-matrix parameters (without normalization)\n",
    "ntheta = len(theta0) - nsegments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Callback function to print the chi2 at each iteration\n",
    "def callback(params, iter, resid):\n",
    "    if( iter % 10 == 0 ): print(\"Iteration: {:6d} it Chi2: {:15.4f}\".format( iter, np.sum(resid**2) ), end=\"\\r\")\n",
    "    pass\n",
    "\n",
    "# Add normalization to chi2\n",
    "def normalization( theta ):\n",
    "    # We use ntheta to loop on normalization parameters with systematic uncertainty\n",
    "    norm = []\n",
    "    for key in norms:\n",
    "        norm.append( (theta[ntheta + key] - norms[key][0]) / norms[key][1] )\n",
    "    return norm\n",
    "\n",
    "# Calculated squared residuals\n",
    "def least_squares( theta ):\n",
    "    output = np.vstack(azr.predict(theta, dress_up=False))\n",
    "    mu, y, dy = output[:, 4], output[:, 7], output[:, 8]    \n",
    "    chi2 = (y - mu) / dy\n",
    "    return chi2\n",
    "\n",
    "#Function to minimize\n",
    "def func( theta ):\n",
    "    theta = list( theta.valuesdict().values() )\n",
    "    residuals = np.concatenate( (least_squares( theta ), normalization( theta )) )\n",
    "    return residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare initial guesses\n",
    "initial_guess = np.array( theta0 )\n",
    "#for i in range( len(theta0) ):\n",
    "# For resonance positions we do not want go to far since AZURE2 crashes\n",
    "#    if( i in [1,5,11] ): initial_guess[i] = np.random.normal( theta0[i], 0.01 )\n",
    "# For the other parameters we can be more free\n",
    "#    else:                initial_guess[i] = np.random.uniform( theta0[i] * 0.5, theta0[i] * 1.5 )\n",
    "\n",
    "# Preparing the parameters\n",
    "params = Parameters()\n",
    "for i in range(len(theta0)):\n",
    "    params.add( \"param_{}\".format(i), value=initial_guess[i], vary=True, min=-np.inf, max=np.inf)\n",
    "\n",
    "# Starting the minimization  \n",
    "mini = Minimizer( func, params, iter_cb=callback )\n",
    "out = mini.minimize( method=method )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run many parallel minimizations\n",
    "#def run_minimization( seed ):\n",
    "#    np.random.seed( seed )\n",
    "#    initial_guess = np.array( theta0 )\n",
    "#    for i in range( len(theta0) ):\n",
    "#        if( i in [1,5,11] ): initial_guess[i] = np.random.normal( theta0[i], 0.01 )\n",
    "#        else:                initial_guess[i] = np.random.uniform( theta0[i] * 0.5, theta0[i] * 1.5 )\n",
    "#    params = Parameters()\n",
    "#    for i in range(len(theta0)):\n",
    "#        params.add( \"param_{}\".format(i), value=initial_guess[i], vary=True )\n",
    "#    mini = Minimizer( func, params, iter_cb=callback )\n",
    "#    out = mini.minimize( method=method )\n",
    "#    return out\n",
    "\n",
    "# Number of parallel minimizations\n",
    "#nparallel = 10\n",
    "#with Pool( nparallel ) as pool:\n",
    "#    results = list( tqdm( pool.imap_unordered( run_minimization, range(nparallel) ), total=nparallel ) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print the chi2 from func\n",
    "chi2 = np.sum( func(out.params)**2 )\n",
    "chi2_red = chi2 / (ndata - len(out.params))\n",
    "display(Math(\"\\chi ^2 = {:20.2f} \\ \\chi ^2 _r = {:20.2f}\".format(chi2, chi2_red)))\n",
    "\n",
    "# Print the minimizer result\n",
    "for i in range(len(theta0)):\n",
    "    label, value, error = azr.config.labels[i], out.params[\"param_{}\".format(i)].value, out.params[\"param_{}\".format(i)].stderr\n",
    "    if( error == None ): error = 0\n",
    "    display(Math(\"{}: {:20.6f} +/- {:15.6f}\".format(label, value, error)))\n",
    "\n",
    "# Write the results to a file\n",
    "with open( \"results/best-{}.txt\".format(method), \"w\" ) as f:\n",
    "    # Write a header with the chi2 and chi2_red, number of iterations, number of data and number of parameters\n",
    "    f.write(\"# Chi2 = {} \\n\".format(chi2))\n",
    "    f.write(\"# Chi2_red = {} \\n\".format(chi2_red))\n",
    "    f.write(\"# Iterations = {} \\n\".format(out.nfev))\n",
    "    f.write(\"# Data = {} \\n\".format(ndata))\n",
    "    f.write(\"# Parameters = {} \\n\".format(len(out.params)))\n",
    "    # Write the parameters\n",
    "    for i in range(len(theta0)):\n",
    "        label, value, error = azr.config.labels[i], out.params[\"param_{}\".format(i)].value, out.params[\"param_{}\".format(i)].stderr\n",
    "        if( error == None ): error = 0\n",
    "        f.write(\"{}: {} +/- {} \\n\".format(label, value, error))\n",
    "\n",
    "# Write the covariance matrix\n",
    "with open( \"results/covariance-{}.txt\".format(method), \"w\" ) as f:\n",
    "    for i in range(len(theta0)):\n",
    "        for j in range(len(theta0)):\n",
    "            f.write(\"{:15.6f} \".format(out.covar[i,j]))\n",
    "        f.write(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation matrix\n",
    "correlation = np.zeros( (len(theta0), len(theta0)) )\n",
    "for i in range(len(theta0)):\n",
    "    for j in range(len(theta0)):\n",
    "        correlation[i,j] = out.covar[i,j] / (out.params[\"param_{}\".format(i)].stderr * out.params[\"param_{}\".format(j)].stderr)\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "# Plot only lower triangle\n",
    "for i in range(len(theta0)):\n",
    "    for j in range(len(theta0)):\n",
    "        if( i <= j ): correlation[i,j] = 0\n",
    "        pass\n",
    "    pass\n",
    "\n",
    "# Generate a mask for the upper triangle\n",
    "mask = np.triu(np.ones_like(correlation, dtype=bool))\n",
    "\n",
    "# Set up the matplotlib figure\n",
    "f, ax = plt.subplots(figsize=(11, 9))\n",
    "\n",
    "# Generate a custom diverging colormap\n",
    "cmap = sns.diverging_palette(230, 20, as_cmap=True)\n",
    "\n",
    "# Draw the heatmap with the mask and correct aspect ratio\n",
    "sns.heatmap(correlation, mask=mask, cmap=cmap, vmax=1, vmin=-1, center=0,\n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})\n",
    "\n",
    "# Set title and labels\n",
    "plt.title(\"Correlation Matrix\")\n",
    "\n",
    "# Change xticks and yticks\n",
    "plt.xticks(range(len(theta0)), azr.config.labels, rotation=90)\n",
    "plt.yticks(range(len(theta0)), azr.config.labels, rotation=0)\n",
    "\n",
    "plt.show( )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get 1000 samples from the covariance matrix\n",
    "samples = np.random.multivariate_normal( list(out.params.valuesdict().values()), out.covar, 1000 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to cut the extrapolations between pp and pg channels\n",
    "def cut( result ):\n",
    "    samples = [ ]\n",
    "    matrix = np.array( result )\n",
    "    # Cut array in the points where the first column, thus the energy, decrease\n",
    "    indexes = np.where( np.diff( matrix[:,0] ) < 0 )[0]\n",
    "    for i in range( len(indexes) + 1 ):\n",
    "        if( i == 0 ): samples.append( matrix[:indexes[i],] )\n",
    "        elif( i == len(indexes) ): samples.append( matrix[indexes[i-1]+1:,] )\n",
    "        else: samples.append( matrix[indexes[i-1]+1:indexes[i],] )\n",
    "    return samples\n",
    "\n",
    "# Calculate the extrapolations\n",
    "buckets = { \"integral\"           : [ ],\n",
    "            \"differential_0deg\"  : [ ],\n",
    "            \"differential_55deg\" : [ ],\n",
    "            \"differential_90deg\" : [ ],\n",
    "            \"elastic_84deg\"      : [ ],\n",
    "            \"elastic_114deg\"     : [ ],\n",
    "            \"elastic_144deg\"     : [ ] }\n",
    "\n",
    "for sample in tqdm( samples ):\n",
    "\n",
    "    # Extrapolate gives an array of extrapolations for each channel\n",
    "    result = azr.extrapolate( sample, ext_capture_file=\"output/intEC.extrap\" )\n",
    "\n",
    "    # In each channel, the data are not divided per segment\n",
    "    samples_pp = cut( result[0] )\n",
    "    samples_pg = cut( result[1] )\n",
    "\n",
    "    # Append the extrapolation to each segment in AZURE2 order\n",
    "    buckets[\"integral\"].append( samples_pg[0] )\n",
    "    buckets[\"differential_0deg\"].append( samples_pg[1] )\n",
    "    buckets[\"differential_55deg\"].append( samples_pg[2] )\n",
    "    buckets[\"differential_90deg\"].append( samples_pg[3] )\n",
    "    buckets[\"elastic_84deg\"].append( samples_pp[0] )\n",
    "    buckets[\"elastic_114deg\"].append( samples_pp[1] )\n",
    "    buckets[\"elastic_144deg\"].append( samples_pp[2] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the correlation between each parameter and each cross section at each energy\n",
    "correlations = {}\n",
    "for key in buckets.keys( ):\n",
    "    array = np.array( buckets[key] )\n",
    "    #print( buckets[key][0][0], array[0][0] )\n",
    "    correlations[key] = np.zeros( (len(theta0), len( array[0][:,0] )) )\n",
    "    for i in range( len(theta0) ):\n",
    "        for k in range( len( array[0][:,0] ) ):\n",
    "            corr = np.corrcoef( samples[:, i], array[:,k][:,4] )[0, 1]\n",
    "            correlations[key][i][k] = corr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the correlation coefficient for each energy point\n",
    "fig, ax = plt.subplots( len( theta0 ), len( buckets ), figsize=(60, 170) )\n",
    "for i, key in enumerate( buckets.keys( ) ):\n",
    "    for j in range( len( theta0 ) ):\n",
    "        x, y = buckets[key][0][:,0], correlations[key][j]\n",
    "        cmap = sns.color_palette(\"coolwarm\", as_cmap=True)\n",
    "        ax[j][i].scatter( x, y, c=y, cmap=cmap, vmin=-1, vmax=1, s=20 )\n",
    "        ax[j][i].set_title( key )\n",
    "        ax[j][i].set_xlabel( \"Energy (MeV)\" )\n",
    "        ax[j][i].set_ylabel( r\"Correlation of {}\".format( azr.config.labels[j] ) )\n",
    "        ax[j][i].set_xlim( 0, x[-1] )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase font size\n",
    "plt.rcParams.update({'font.size': 15})\n",
    "\n",
    "# Plotting the cross sections\n",
    "fig, ax = plt.subplots( 3, 3, figsize=( 20, 20 ) )\n",
    "\n",
    "for i, key in enumerate( buckets.keys( ) ):\n",
    "\n",
    "    bucket = buckets[key]\n",
    "\n",
    "    # Calculate the mean and standard deviation\n",
    "    mean = np.mean( bucket, axis=0 )\n",
    "    std  = np.std( bucket, axis=0 )\n",
    "    \n",
    "    ax[i//3, i%3].set_title( key )\n",
    "    ax[i//3, i%3].set_xlabel( \"Energy (MeV)\" )\n",
    "    ax[i//3, i%3].set_ylabel( \"S-factor (MeV b)\" )\n",
    "    \n",
    "    ax[i//3, i%3].plot( mean[:,0], mean[:,4], label=\"Extrapolation\", color=\"red\" )\n",
    "    ax[i//3, i%3].fill_between( mean[:,0], mean[:,4] - std[:,4], mean[:,4] + std[:,4], color=\"red\", alpha=0.5 )\n",
    "\n",
    "    if( key == \"integral\" ): \n",
    "        ax[i//3, i%3].errorbar( data[\"skowronski_luna_hpge.dat\"][:,0], data[\"skowronski_luna_hpge.dat\"][:,4], yerr=data[\"skowronski_luna_hpge.dat\"][:,5], label=\"LUNA HPGe\", fmt=\"o\" )\n",
    "        ax[i//3, i%3].errorbar( data[\"skowronski_luna_bgo.dat\"][:,0], data[\"skowronski_luna_bgo.dat\"][:,4], yerr=data[\"skowronski_luna_bgo.dat\"][:,5], label=\"LUNA BGO\", fmt=\"o\" )\n",
    "        ax[i//3, i%3].errorbar( data[\"skowronski_fels.dat\"][:,0], data[\"skowronski_fels.dat\"][:,4], yerr=data[\"skowronski_fels.dat\"][:,5], label=\"LUNA BGO\", fmt=\"o\" )\n",
    "        ax[i//3, i%3].errorbar( data[\"vogl.dat\"][:,0], data[\"vogl.dat\"][:,7], yerr=data[\"vogl.dat\"][:,8], label=\"Vogl\", fmt=\"o\" )\n",
    "        ax[i//3, i%3].errorbar( data[\"gyurky.dat\"][:,0], data[\"gyurky.dat\"][:,7], yerr=data[\"gyurky.dat\"][:,8], label=\"Gyurky\", fmt=\"o\" )\n",
    "        ax[i//3, i%3].errorbar( data[\"burtebaev.dat\"][:,0], data[\"burtebaev.dat\"][:,7], yerr=data[\"burtebaev.dat\"][:,8], label=\"Burtebaev\", fmt=\"o\" )\n",
    "        ax[i//3, i%3].errorbar( data[\"lamb.dat\"][:,0], data[\"lamb.dat\"][:,7], yerr=data[\"lamb.dat\"][:,8], label=\"Vogl\", fmt=\"o\" )\n",
    "        ax[i//3, i%3].errorbar( data[\"bailey.dat\"][:,0], data[\"bailey.dat\"][:,7], yerr=data[\"bailey.dat\"][:,8], label=\"Vogl\", fmt=\"o\" )\n",
    "        ax[i//3, i%3].set_xlim(0, 2.5)\n",
    "\n",
    "    if( key == \"differential_0deg\" ):\n",
    "        mask = (data[\"rolfs.dat\"][:,2] == 0)\n",
    "        ax[i//3, i%3].errorbar( data[\"rolfs.dat\"][mask][:,0], data[\"rolfs.dat\"][mask][:,7], yerr=data[\"rolfs.dat\"][mask][:,8], label=\"Rolfs\", fmt=\"o\" )\n",
    "        mask = (data[\"kettner.dat\"][:,2] == 0)\n",
    "        ax[i//3, i%3].errorbar( data[\"kettner.dat\"][mask][:,0], data[\"kettner.dat\"][mask][:,7], yerr=data[\"kettner.dat\"][mask][:,8], label=\"Kettner\", fmt=\"o\" )\n",
    "        ax[i//3, i%3].set_xlim(0, 2.5)\n",
    "\n",
    "    if( key == \"differential_55deg\" ):\n",
    "        mask = (data[\"kettner.dat\"][:,2] == 55)\n",
    "        ax[i//3, i%3].errorbar( data[\"kettner.dat\"][mask][:,0], data[\"kettner.dat\"][mask][:,7], yerr=data[\"kettner.dat\"][mask][:,8], label=\"Kettner\", fmt=\"o\" )\n",
    "        ax[i//3, i%3].set_xlim(0, 2.5)\n",
    "\n",
    "    if( key == \"differential_90deg\" ):\n",
    "        mask = (data[\"rolfs.dat\"][:,2] == 90)\n",
    "        ax[i//3, i%3].errorbar( data[\"rolfs.dat\"][mask][:,0], data[\"rolfs.dat\"][mask][:,7], yerr=data[\"rolfs.dat\"][mask][:,8], label=\"Rolfs\", fmt=\"o\" )\n",
    "        ax[i//3, i%3].set_xlim(0, 2.5)\n",
    "\n",
    "    if( key == \"elastic_84deg\" ):\n",
    "        mask = (data[\"meyer.dat\"][:,2] == 89.09121)\n",
    "        ax[i//3, i%3].errorbar( data[\"meyer.dat\"][mask][:,0], data[\"meyer.dat\"][mask][:,7], yerr=data[\"meyer.dat\"][mask][:,8], label=\"Meyer\", fmt=\"o\" )\n",
    "        ax[i//3, i%3].set_ylim(1e0, 1e5)\n",
    "\n",
    "    if( key == \"elastic_114deg\" ):\n",
    "        mask = (data[\"meyer.dat\"][:,2] == 118.8806)\n",
    "        ax[i//3, i%3].errorbar( data[\"meyer.dat\"][mask][:,0], data[\"meyer.dat\"][mask][:,7], yerr=data[\"meyer.dat\"][mask][:,8], label=\"Meyer\", fmt=\"o\" )\n",
    "\n",
    "    if( key == \"elastic_144deg\" ):\n",
    "        mask = (data[\"meyer.dat\"][:,2] == 146.9212)\n",
    "        ax[i//3, i%3].errorbar( data[\"meyer.dat\"][mask][:,0], data[\"meyer.dat\"][mask][:,7], yerr=data[\"meyer.dat\"][mask][:,8], label=\"Meyer\", fmt=\"o\" )\n",
    "        ax[i//3, i%3].set_ylim(1e-1, 1e5)\n",
    "\n",
    "    ax[i//3, i%3].legend( ncol=2, fontsize=12 )\n",
    "    ax[i//3, i%3].set_yscale( \"log\" )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.1.undefined"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
